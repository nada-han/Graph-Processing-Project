version: "3.8"
services:
  # Spark Master
  spark-master:
    image: bitnami/spark:latest
    container_name: spark-master
    environment:
      - SPARK_MODE=master
    ports:
      - "4040:4040"  # Spark UI
      - "7077:7077"  # Spark Master
    networks:
      - graph-network
    volumes:
      - ./data:/app/data

  # Spark Worker
  spark-worker:
    image: bitnami/spark:latest
    container_name: spark-worker1
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    depends_on:
      - spark-master
    ports:
      - "8081:8081"  # Spark Worker UI
    networks:
      - graph-network
    volumes:
      - ./data:/app/data

  # Hadoop NameNode
  hadoop-namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop2.7.4-java8
    container_name: hadoop-namenode
    environment:
      - CLUSTER_NAME=hadoop-cluster
    ports:
      - "8099:50070"  # HDFS NameNode Web UI
    volumes:
      - hadoop-namenode-data:/hadoop/dfs/name
    networks:
      - graph-network

  # Hadoop DataNode
  hadoop-datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8
    container_name: hadoop-datanode
    environment:
      - CLUSTER_NAME=hadoop-cluster
      - NAMENODE_URI=hdfs://hadoop-namenode:8020
    ports:
      - "9864:50075"  # DataNode Web UI
    volumes:
      - hadoop-datanode-data:/hadoop/dfs/data
    depends_on:
      - hadoop-namenode
    networks:
      - graph-network

  # Neo4j
  neo4j:
    image: neo4j:5
    container_name: neo4j
    environment:
      - NEO4J_AUTH=none
    ports:
      - "7474:7474"  # Neo4j Browser
      - "7687:7687"  # Bolt Protocol
    volumes:
      - neo4j_data:/data
      - ./datasets:/datasets
    networks:
      - graph-network
      - stream-net

  # Streamlit
  streamlit:
    image: samdobson/streamlit
    build:
      context: ./streamlit_app
    container_name: streamlit
    ports:
      - "8501:8501"
    volumes:
      - ./streamlit_app:/app
    networks:
      - graph-network
      - stream-net

  # Kafka Zookeeper
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - kafka-net

  # Kafka Broker
  broker:
    image: confluentinc/cp-kafka:7.4.0
    container_name: broker
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "9101:9101"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL: PLAINTEXT
    networks:
      - kafka-net
    healthcheck:
      test: ["CMD", "bash", "-c", 'nc -z broker 9092']
      interval: 10s
      timeout: 5s
      retries: 5

  # The Apache airflow webserver
  airflow-git:
    image : airflow-git:latest
    container_name: airflow
    build:
      context: ./airflow
    volumes :
      - ./airflow:/opt/airflow
    ports :
      - "8084:8080"
    command : airflow standalone
    networks:
      - kafka-net
      - graph-network

  # Initializing the postgres service
  postgres:
    image: postgres:14.0
    container_name: postgres
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    ports:
      - "5432:5432"
    networks:
      - kafka-net
      - graph-network
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 10s
      retries: 5
      timeout: 5s

  # Zeppelin
  zeppelin:
    image: apache/zeppelin:0.10.0
    container_name: zeppelin1
    depends_on:
      - spark-master
    ports:
      - "8082:8080"
    environment:
      - ZEPPELIN_ADDR=0.0.0.0
      - ZEPPELIN_SPARK_MASTER=spark://spark-master:7077
      - ZEPPELIN_NOTEBOOK_DIR=/zeppelin/notebook
    volumes:
      - zeppelin_data:/zeppelin/data
      - ./zeppelin/notebook:/zeppelin/notebook
    networks:
      - graph-network

  # Flask App
  flask-app:
    build: .
    container_name: flask-app
    ports:
      - "5000:5000"
    depends_on:
      - broker
    environment:
      - KAFKA_BROKER=broker:9092
    networks:
      - kafka-net
      - graph-network
    volumes:
      - ./app:/app


volumes:
  neo4j_data:
  zeppelin_data:
  hadoop-namenode-data:
  hadoop-datanode-data:

networks:
  graph-network:
    driver: bridge
  kafka-net:
    external: true
  stream-net:
    external: true